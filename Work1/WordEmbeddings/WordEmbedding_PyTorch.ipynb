{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WordEmbedding_PyTorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMN1k7CH9lqP5xrmzrSq59D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install datasets"],"metadata":{"id":"Yw1GJ-aQ90A7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYnH53fX6Icr","executionInfo":{"status":"ok","timestamp":1661565316974,"user_tz":240,"elapsed":165,"user":{"displayName":"Krishna Adatrao","userId":"02346538922411399655"}},"outputId":"5722f87b-8bcd-4f57-ca94-9396814b2e6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7ff435d9f990>"]},"metadata":{},"execution_count":37}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torchtext\n","import torchvision\n","import tarfile\n","import datasets as ds\n","from torch.hub import load_state_dict_from_url\n","from torch.nn import Embedding\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","torch.manual_seed(1)"]},{"cell_type":"code","source":["qqp_dataset = ds.load_dataset('glue', 'qqp', split = 'train')  \n","print(qqp_dataset.shape)\n","qqp_df = qqp_dataset.to_pandas()\n","df_qqp = qqp_df.head(100)\n","df_qqp"],"metadata":{"id":"p4twLiL-7G9n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["questions_list = list(df_qqp['question1'])\n","splitted = [i.split() for i in questions_list]\n","splitted"],"metadata":{"id":"IT0E8BytIk8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cola_dataset = ds.load_dataset('glue', 'cola', split = 'train') \n","print(cola_dataset.shape)\n","cola_df = cola_dataset.to_pandas()\n","df_cola = cola_df.head(100)\n","print(df_cola.shape)"],"metadata":{"id":"wOiwx2hsdlIS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cola_sentences = df_cola['sentence']\n","cola_list = list(cola_sentences)\n","cola_split = [i.split() for i in cola_list]\n","cola_club = []\n","for i in cola_split:\n","  for j in i:\n","    cola_club.append(j)\n","cola_club"],"metadata":{"id":"SnHdfW7sI7H8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["freq = 2\n","emb_dimensions = 100\n","Language_model_build_Ngram = [\n","    (\n","        [cola_club[i - j - 1] for j in range(freq)],\n","        cola_club[i]\n","    )\n","    for i in range(freq, len(cola_club))\n","]\n","# Print the first 3, just so you can see what they look like.\n","print(Language_model_build_Ngram[:3])\n","\n","terminology = set(cola_club)\n","dict_index = {word: i for i, word in enumerate(terminology)}\n","\n","\n","class LM_Ngram(nn.Module):\n","\n","    def __init__(self, terminology_size, emb_dimensions, freq):\n","        super(LM_Ngram, self).__init__()\n","        self.embd = nn.Embedding(terminology_size, emb_dimensions)\n","        self.lin1 = nn.Linear(freq * emb_dimensions, 128)\n","        self.lin2 = nn.Linear(128, terminology_size)\n","\n","    def forward(self, inputs):\n","        embds = self.embd(inputs).view((1, -1))\n","        out = F.relu(self.lin1(embds))\n","        out = self.lin2(out)\n","        model_log = F.log_softmax(out, dim=1)\n","        return model_log\n","\n","\n","wastage = []\n","loss_func = nn.NLLLoss()\n","model_build = LM_Ngram(len(terminology), emb_dimensions, freq)\n","optimum_build = optim.SGD(model_build.parameters(), lr=0.001)\n","\n","for e in range(10):\n","    agg_loss = 0\n","    for context, target in Language_model_build_Ngram:\n","\n","        # Step 1. Prepare the inputs to be passed to the model_build (i.e, turn the words\n","        # into integer indices and wrap them in tensors)\n","        term_index_log = torch.tensor([dict_index[w] for w in context], dtype=torch.long)\n","\n","        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n","        # new instance, you need to zero out the gradients from the old\n","        # instance\n","        model_build.zero_grad()\n","\n","        # Step 3. Run the forward pass, getting log probabilities over next\n","        # words\n","        model_log = model_build(term_index_log)\n","\n","        # Step 4. Compute your loss function. (Again, Torch wants the target\n","        # word wrapped in a tensor)\n","        loss = loss_func(model_log, torch.tensor([dict_index[target]], dtype=torch.long))\n","\n","        # Step 5. Do the backward pass and update the gradient\n","        loss.backward()\n","        optimum_build.step()\n","\n","        # Get the Python number from a 1-element Tensor by calling tensor.item()\n","        agg_loss += loss.item()\n","    wastage.append(agg_loss)\n","print(wastage)  # The loss decreased every iteration over the training info!\n","\n","# To get the embedding of a particular word, e.g. \"beauty\"\n","print(model_build.embd.weight[dict_index[\"friends\"]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B25ctD0eJOom","executionInfo":{"status":"ok","timestamp":1661570173635,"user_tz":240,"elapsed":4587,"user":{"displayName":"Krishna Adatrao","userId":"02346538922411399655"}},"outputId":"13162cb4-df5e-4a74-e0b3-29bc1c0f16f2"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["[(['friends', 'Our'], \"won't\"), ([\"won't\", 'friends'], 'buy'), (['buy', \"won't\"], 'this')]\n","[3588.069879055023, 3480.4721961021423, 3368.556111097336, 3249.9172459840775, 3135.2240887880325, 3040.3954313099384, 2962.2679595798254, 2891.4134205579758, 2823.377431035042, 2756.0928336530924]\n","tensor([ 0.2396,  0.0502,  0.9585,  0.2359, -1.3063,  0.4543,  0.5654, -1.0022,\n","        -1.5026, -1.5885,  0.0306,  0.2366, -0.8308, -1.3930, -0.0421, -0.3654,\n","        -0.6799,  0.7382, -1.1749,  0.2314, -0.8781,  0.0135, -2.2154,  0.1822,\n","        -1.6944,  1.2787,  0.6896, -0.3323,  0.4410, -0.0276, -0.3023, -1.1430,\n","         1.1011, -0.7633, -0.6471,  0.6249, -1.0654, -0.4269, -0.4138, -0.7262,\n","         0.3140,  0.6562, -0.2120,  1.0820,  0.0158, -0.9244,  0.1684,  0.3090,\n","         0.6645,  0.1435, -1.0088, -0.2322,  1.1397, -0.9765,  0.4586, -1.0782,\n","         1.0066, -0.5182,  0.7757,  0.0117,  0.0998, -0.1655,  0.7795, -0.5502,\n","        -2.4609, -0.9725,  0.4809,  0.9322, -0.3171, -1.2726, -0.0961,  0.1144,\n","         0.0749,  0.3877,  0.4513, -0.7307,  1.1073, -0.9764,  0.0427, -1.2000,\n","         1.4531,  0.7387,  0.4875, -0.2592,  0.2205,  0.6413, -0.0483,  1.9405,\n","        -0.3328,  0.8939,  0.8539, -0.3011,  0.6914, -1.3593,  1.1846,  1.2292,\n","         1.1319, -0.4630, -1.3190, -1.9036], grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"code","source":["terminology = set(cola_club)\n","terminology_size = len(terminology)\n","\n","dict_index = {word: i for i, word in enumerate(terminology)}\n","info = []\n","for i in range(freq, len(cola_club) - freq):\n","    context = (\n","        [cola_club[i - j - 1] for j in range(freq)]\n","        + [cola_club[i + j + 1] for j in range(freq)]\n","    )\n","    target = cola_club[i]\n","    info.append((context, target))\n","print(info[:5])\n","\n","\n","class module_class(nn.Module):\n","\n","    def __init__(self):\n","        pass\n","\n","    def forward(self, inputs):\n","        pass\n","\n","# Create your model_build and train. Here are some functions to help you make\n","# the info ready for use by your module.\n","\n","\n","def term_vector(context, dict_index):\n","    indexes = [dict_index[w] for w in context]\n","    return torch.tensor(indexes, dtype=torch.long)\n","\n","\n","term_vector(info[0][0], dict_index)"],"metadata":{"id":"oNXCYpoFJxMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661570204419,"user_tz":240,"elapsed":197,"user":{"displayName":"Krishna Adatrao","userId":"02346538922411399655"}},"outputId":"f78b104e-cb2b-4458-b2c4-d365c403b1b9"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["[(['friends', 'Our', 'buy', 'this'], \"won't\"), ([\"won't\", 'friends', 'this', 'analysis,'], 'buy'), (['buy', \"won't\", 'analysis,', 'let'], 'this'), (['this', 'buy', 'let', 'alone'], 'analysis,'), (['analysis,', 'this', 'alone', 'the'], 'let')]\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([122, 179, 243,  61])"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","source":["Reference - https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html "],"metadata":{"id":"4sltBO9Z_Npv"}},{"cell_type":"code","source":[],"metadata":{"id":"Lpa56wrziByV"},"execution_count":null,"outputs":[]}]}